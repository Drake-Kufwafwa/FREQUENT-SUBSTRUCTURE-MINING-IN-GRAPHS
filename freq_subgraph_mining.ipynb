{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 4 - Final Project\n",
    "\n",
    "## _Mining Frequent Subgraphs_\n",
    "Harris Mahmood Khawar, Paul Jackson, Drake Kufwafwa, Henry Fox-Jurkowitz  \n",
    "_COSC-254: Data Mining_  \n",
    "Professor Matteo Riondato \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This project also contains test datasets created by us, which can be used to ensure the accuracy of the algorithms.<br>\n",
    "The file: ```test-graph-desc.pdf``` contains information about the test datasets (incl. expected results).\n",
    "\n",
    "Please find the ```Main``` cell to choose input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap\n",
    "import glob\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "\n",
    "# return list of graphs in given directory\n",
    "def get_graph_database(dir_path):\n",
    "    graph_paths = glob.glob(dir_path)\n",
    "    graph_database = []\n",
    "    \n",
    "    for path in graph_paths:\n",
    "        graph_database.append(snap.LoadEdgeList(snap.TUNGraph, path, 0, 1))\n",
    "    \n",
    "    return graph_database\n",
    "\n",
    "\n",
    "#returns list of randomly generated undirected graphs\n",
    "def get_random_graph_database(numEdges, numNodes, numGraphs):\n",
    "    graph_database=[]\n",
    "\n",
    "    for i in range(numGraphs):\n",
    "        graph_database.append(snap.GenRndGnm(snap.TUNGraph, numNodes, numEdges, False))        \n",
    "    \n",
    "    return graph_database\n",
    "\n",
    "\n",
    "# return all graph edges as list\n",
    "def list_graph(graph):\n",
    "    graph_list = []\n",
    "    \n",
    "    if graph.GetEdges() == 0:\n",
    "        for N in graph.Nodes():\n",
    "            graph_list.append(N.GetId())\n",
    "    else:\n",
    "        for E in graph.Edges():\n",
    "            curr_edge = (E.GetSrcNId(), E.GetDstNId())\n",
    "            graph_list.append(curr_edge)\n",
    "    \n",
    "    return graph_list\n",
    "         \n",
    "\n",
    "# print graphs and their supports / print dict\n",
    "def print_dict(D, opt):\n",
    "    if opt == \"graph\":\n",
    "        for graph in D.keys():\n",
    "            print(\"Graph: {}, Support: {}\".format(list_graph(graph), D[graph]))    \n",
    "    else:\n",
    "        for key in D.keys():\n",
    "            print(\"Key : {} , Value : {}\".format(key, D[key]))\n",
    "\n",
    "# return true if given graphs are the same\n",
    "def compare_graphs(G1, G2):\n",
    "    \n",
    "    if G1.GetNodes() != G2.GetNodes() or G1.GetEdges() != G2.GetEdges(): \n",
    "        return False\n",
    "    \n",
    "    for N in G1.Nodes():\n",
    "        if not G2.IsNode(N.GetId()): return False\n",
    "    \n",
    "    for E in G1.Edges():\n",
    "        if not G2.IsEdge(E.GetSrcNId(), E.GetDstNId()): return False\n",
    "        \n",
    "    return True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node-based Join Growth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node-based Join Growth\n",
    "\n",
    "'''\n",
    "NOTE: (get_all_node_supports) \n",
    "This method assumes that there are no label repitions in any of the graphs.\n",
    "That is, none of the graphs have more than one node with ID x.\n",
    "'''\n",
    "# return dict with all nodes in g and their support\n",
    "def get_all_node_supports(graph_database):\n",
    "    NS = {}\n",
    "    \n",
    "    for graph in graph_database:\n",
    "        for N in graph.Nodes():\n",
    "            curr_node = N.GetId()\n",
    "            if curr_node in NS:\n",
    "                NS[curr_node] += 1\n",
    "            else:\n",
    "                NS[curr_node] = 1\n",
    "    \n",
    "    return NS\n",
    "\n",
    "\n",
    "# return dict with frequent singleton graphs and their supports\n",
    "def get_frequent_singleton_graphs(NS, minsup):\n",
    "    F1 = {}\n",
    "    \n",
    "    for N in NS:\n",
    "        if NS[N] >= minsup:\n",
    "            subgraph = snap.TUNGraph.New() # create new graph\n",
    "            subgraph.AddNode(N) # add frequent node\n",
    "            F1[subgraph] = NS[N] # graph support = node support\n",
    "    \n",
    "    return F1\n",
    "\n",
    "\n",
    "# return candidate by joining singletons\n",
    "def join_singletons(subgraph1, subgraph2):\n",
    "    c = snap.TUNGraph.New() # new candidate subgraph\n",
    "    c = snap.ConvertGraph(type(subgraph1), subgraph1)\n",
    "    \n",
    "    c.AddNode(subgraph2.BegNI().GetId()) # add subgraph2 node to subgraph1\n",
    "    c.AddEdge(subgraph1.BegNI().GetId(), subgraph2.BegNI().GetId()) # add edge between nodes\n",
    "        \n",
    "    return c\n",
    "\n",
    "'''\n",
    "NOTE: (subgraph_match)\n",
    "The book recommends Ullman's Algorithm for this,\n",
    "which is recursive. I am not a fan recursion so I made the following,\n",
    "which might not be as efficient but does the job.\n",
    "'''\n",
    "# return node and edge if they are the only non-matching ones\n",
    "def subgraph_match(Gq, G):\n",
    "    nmE_f = False # non-matching node found\n",
    "    nmN_f = False # non-matching edge found\n",
    "    nmN = None # non_matching node\n",
    "    nmE = None # non-matching edge\n",
    "\n",
    "    res = False\n",
    "\n",
    "    for E in Gq.Edges():\n",
    "        if not G.IsEdge(E.GetSrcNId(), E.GetDstNId()):\n",
    "            if nmE_f:\n",
    "                nmE_f = False\n",
    "                break\n",
    "            else:\n",
    "                nmE = (E.GetSrcNId(), E.GetDstNId())\n",
    "                nmE_f = True\n",
    "    \n",
    "    if nmE_f:\n",
    "        for N in Gq.Nodes():\n",
    "            if not G.IsNode(N.GetId()):\n",
    "                if nmN_f:\n",
    "                    nmN_f = False\n",
    "                    break\n",
    "                else:\n",
    "                    nmN = N.GetId()\n",
    "                    if nmN in nmE:\n",
    "                        nmN_f = True\n",
    "                    else:\n",
    "                        break\n",
    "                        \n",
    "    if nmN_f and nmE_f:\n",
    "        res = True\n",
    "    \n",
    "    return res, nmE, nmN\n",
    "\n",
    "\n",
    "# return candidates by performing node-based joins    \n",
    "def join_subgraphs(subgraph1, subgraph2, nmE, nmN):\n",
    "    \n",
    "    # create new candidate subgraphs\n",
    "    c1 = snap.TUNGraph.New()\n",
    "    c2 = snap.TUNGraph.New()\n",
    "    \n",
    "    # hold non-matching node in subgraph2\n",
    "    for N in subgraph2.Nodes():\n",
    "        if not subgraph1.IsNode(N.GetId()):\n",
    "            nmN_s2 = N.GetId()\n",
    "    \n",
    "    c1 = snap.ConvertGraph(type(subgraph2), subgraph2) # copy subgraph1\n",
    "    c1.AddNode(nmN) # add non-matching node from subgraph1\n",
    "    c1.AddEdge(nmE[0], nmE[1]) # add non-matching edge\n",
    "    \n",
    "    c2 = snap.ConvertGraph(type(c1), c1) # copy candidate 1\n",
    "    c2.AddEdge(nmN, nmN_s2) # add edge between non-matching nodes of subgraph1 and subgraph2\n",
    "    \n",
    "    return c1, c2\n",
    "\n",
    "# return true if all k-1 subgraphs of candidate are in Fk\n",
    "def prune_candidate(c, Fk, k):\n",
    "    all_edges = []\n",
    "    \n",
    "    for E in c.Edges():\n",
    "        all_edges.append((E.GetSrcNId(), E.GetDstNId()))\n",
    "    \n",
    "    # generate all edges subsets\n",
    "    kMinus1_subsets = list(itertools.combinations(all_edges, k-2))\n",
    "    \n",
    "    for subset in kMinus1_subsets:\n",
    "        sG = snap.TUNGraph.New()\n",
    "        exists = False\n",
    "        \n",
    "        for tup in subset:\n",
    "            for N in tup:\n",
    "                if not sG.IsNode(N): sG.AddNode(N)\n",
    "            sG.AddEdge(tup[0], tup[1])\n",
    "        \n",
    "        if sG.GetNodes() < k: \n",
    "            for graph in Fk:\n",
    "                if compare_graphs(graph, sG):\n",
    "                    exists = True\n",
    "                    break\n",
    "\n",
    "            if not exists:\n",
    "                return False\n",
    "        \n",
    "    return True \n",
    "\n",
    "'''\n",
    "NOTE: (generate_candidates)\n",
    "This method is incomplete i.e. no optimization/pruning of candidates\n",
    "'''\n",
    "# return candidates list by joining graphs in Fk\n",
    "def generate_candidates(Fk, k):\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(0, len(Fk)):\n",
    "        sG1 = Fk[i]\n",
    "        \n",
    "        for j in range(i+1, len(Fk)):\n",
    "            sG2 = Fk[j]\n",
    "            \n",
    "            # if graphs are from F1, simply join them\n",
    "            if k == 2:\n",
    "                c = join_singletons(sG1, sG2)\n",
    "                candidates.append(c)\n",
    "            \n",
    "            # if graphs are from Fk where k > 1,\n",
    "            else:\n",
    "                # join if they each have only one uncommon node\n",
    "                match, nmE, nmN = subgraph_match(sG1, sG2)\n",
    "                if match:\n",
    "                    c1, c2 = join_subgraphs(sG1, sG2, nmE, nmN)\n",
    "                    for _c in c1, c2:\n",
    "                        if prune_candidate(_c, Fk, k):\n",
    "                            candidates.append(_c)\n",
    "    \n",
    "    return candidates\n",
    "        \n",
    "    \n",
    "# generate frequent k+1 sized graphs dict by counting C in g\n",
    "def generate_Fkplus1(C, g, minsup):\n",
    "    Fkplus1 = {}\n",
    "    candidate_is_subgraph = True\n",
    "    support = 0\n",
    "    \n",
    "    for candidate in C:\n",
    "        for graph in g:\n",
    "\n",
    "            # check if graph contains all candidate's nodes\n",
    "            for N in candidate.Nodes():\n",
    "                if not graph.IsNode(N.GetId()):\n",
    "                    candidate_is_subgraph = False\n",
    "                    break\n",
    "\n",
    "            # check if graph contains all candidate's edges    \n",
    "            if candidate_is_subgraph:        \n",
    "                for E in candidate.Edges():\n",
    "                    if not graph.IsEdge(E.GetSrcNId(), E.GetDstNId()):\n",
    "                        candidate_is_subgraph = False\n",
    "                        break\n",
    "\n",
    "            # increment support            \n",
    "            if candidate_is_subgraph:\n",
    "                support += 1\n",
    "\n",
    "            # reset for next graph\n",
    "            candidate_is_subgraph = True\n",
    "\n",
    "        if support >= minsup:\n",
    "            Fkplus1[candidate] = support\n",
    "\n",
    "        support = 0 # reset support for next candidate\n",
    "    \n",
    "    return Fkplus1\n",
    "\n",
    "\n",
    "'''\n",
    "NOTE: (update_FsG)\n",
    "This method is not optimized because it is not necessary.\n",
    "But it is used because if there cycles in the graphs,\n",
    "duplicate entries are appended to FsG\n",
    "'''\n",
    "# return FsG after appending subgraphs not in FsG from Fk\n",
    "def update_FsG(Fk, FsG):\n",
    "    exists = False\n",
    "    \n",
    "    # compare each graph in Fk with each graph in FsG\n",
    "    for g in Fk.keys(): \n",
    "        \n",
    "        for G in FsG.keys():\n",
    "            \n",
    "            if compare_graphs(g, G):\n",
    "                exists = True\n",
    "                \n",
    "        if not exists:\n",
    "            FsG[g] = Fk[g]\n",
    "            \n",
    "        exists = False\n",
    "        \n",
    "    return FsG\n",
    "\n",
    "\n",
    "# return dict with frequent subgraphs and support\n",
    "def node_based_join_growth(g, minsup):\n",
    "#     t0 = time.time()\n",
    "    # NS = { [(NodeId) : Support] }\n",
    "    NS = get_all_node_supports(g)\n",
    "#     t1 = time.time()\n",
    "#     print(\"Time for node support count: {:.3f}\".format(t1-t0))\n",
    "    \n",
    "    # F1 = { All frequent singleton graphs }\n",
    "    Fk = get_frequent_singleton_graphs(NS, minsup) # frequent k subgraphs\n",
    "    k = 1\n",
    "    \n",
    "    FsG = {} # all frequent subgraphs\n",
    "    C = [] # candidates from Fk\n",
    "    \n",
    "    # Apriori Algorithm:\n",
    "    while(True):\n",
    "#         print(\"Run no. : \", k)\n",
    "#         t0 = time.time()\n",
    "        C = generate_candidates(list(Fk.keys()), k+1)\n",
    "#         t1 = time.time()\n",
    "#         print(\"Time for candidate generation: {:.3f}\".format(t1-t0))\n",
    "        \n",
    "#         t0 = time.time()\n",
    "        Fk = generate_Fkplus1(C, g, minsup)\n",
    "#         t1 = time.time()\n",
    "#         print(\"Time for Fkplus1 generation: {:.3f}\".format(t1-t0))\n",
    "\n",
    "        # end if no more frequent subgraphs\n",
    "        if not Fk: \n",
    "            break\n",
    "        \n",
    "#         t0 = time.time()\n",
    "        FsG = update_FsG(Fk, FsG) # append all frequent subgraphs\n",
    "#         t1 = time.time()\n",
    "#         print(\"Time for update_FsG: {:.3f}\".format(t1-t0))\n",
    "        \n",
    "        k = k + 1\n",
    "    \n",
    "    return FsG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge-based Join Growth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge-based Join Growth\n",
    "\n",
    "'''\n",
    "NOTE: (get_all_edge_supports)\n",
    "This method takes duplication into account.\n",
    "That is, the edges NodeX-NodeY and NodeY-NodeX are considered the same.\n",
    "''' \n",
    "# return dict will all edges in graph database and their supports\n",
    "def get_all_edge_supports(graph_database):\n",
    "        ES = {}    \n",
    "        \n",
    "        for graph in graph_database:\n",
    "            for E in graph.Edges():\n",
    "                curr_edge = (E.GetSrcNId(), E.GetDstNId())\n",
    "                curr_edge_flip = (E.GetDstNId(), E.GetSrcNId())\n",
    "                if curr_edge in ES:\n",
    "                    ES[curr_edge] += 1\n",
    "                elif curr_edge_flip in ES:\n",
    "                    ES[curr_edge_flip] += 1\n",
    "                else:    \n",
    "                    ES[curr_edge] = 1\n",
    "        \n",
    "        return ES\n",
    "\n",
    "\n",
    "# return all edges that have at least minsup support   \n",
    "def get_frequent_singleton_graphs_EB(ES, minsup):\n",
    "    F1 = {}\n",
    "    \n",
    "    for E in ES:\n",
    "        if ES[E] >= minsup:\n",
    "            subgraph = snap.TUNGraph.New()\n",
    "            subgraph.AddNode(E[0])\n",
    "            subgraph.AddNode(E[1])\n",
    "            subgraph.AddEdge(E[0], E[1])\n",
    "            F1[subgraph] = ES[E]\n",
    "\n",
    "    return F1\n",
    "\n",
    "\n",
    "'''\n",
    "NOTE: (subgraph_match_EB)\n",
    "The book recommends Ullman's Algorithm for this,\n",
    "which is recursive. I am not a fan recursion so I made the following,\n",
    "which might not be as efficient but does the job.\n",
    "'''\n",
    "# return node and edge if they are the only non-matching ones\n",
    "def subgraph_match_EB(sG1, sG2): \n",
    "    nmE_f = False # non-matching node found\n",
    "    nmE = None # non-matching edge\n",
    "    \n",
    "    for E in sG1.Edges():\n",
    "        if not sG2.IsEdge(E.GetSrcNId(), E.GetDstNId()):\n",
    "            if nmE_f:\n",
    "                nmE_f = False\n",
    "                break\n",
    "            else:\n",
    "                nmE = (E.GetSrcNId(), E.GetDstNId())\n",
    "                nmE_f = True\n",
    "    \n",
    "    if nmE_f:\n",
    "        if sG2.IsNode(nmE[0]) and sG2.IsNode(nmE[1]):\n",
    "            return True, nmE, None\n",
    "        elif sG2.IsNode(nmE[0]):\n",
    "            return True, nmE, nmE[1]\n",
    "        elif sG2.IsNode(nmE[1]):\n",
    "            return True, nmE, nmE[0]\n",
    "    \n",
    "    return False, None, None\n",
    "    \n",
    "\n",
    "# return candidates by performing node-based joins        \n",
    "def join_subgraphs_EB(subgraph1, subgraph2, nmE, nmN):\n",
    "    \n",
    "    c = snap.ConvertGraph(type(subgraph2), subgraph2)\n",
    "\n",
    "    if nmN is not None:\n",
    "        c.AddNode(nmN)\n",
    "\n",
    "    c.AddEdge(nmE[0], nmE[1])\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "# return true if all k-1 subgraphs of candidate are in Fk\n",
    "def prune_candidate_EB(c, Fk, k):\n",
    "    all_edges = []\n",
    "    \n",
    "    for E in c.Edges():\n",
    "        all_edges.append((E.GetSrcNId(), E.GetDstNId()))\n",
    "    \n",
    "    # generate all edges subsets\n",
    "    kMinus1_subsets = list(itertools.combinations(all_edges, len(all_edges)-1))\n",
    "\n",
    "    for subset in kMinus1_subsets:\n",
    "        sG = snap.TUNGraph.New()\n",
    "        exists = False\n",
    "        \n",
    "        for tup in subset:\n",
    "            for N in tup:\n",
    "                if not sG.IsNode(N): sG.AddNode(N)\n",
    "            sG.AddEdge(tup[0], tup[1])\n",
    "        \n",
    "        if sG.GetNodes() <= len(all_edges):\n",
    "            for graph in Fk:\n",
    "                if compare_graphs(graph, sG):\n",
    "                    exists = True\n",
    "                    break\n",
    "\n",
    "            if not exists:\n",
    "                return False\n",
    "        \n",
    "    return True \n",
    "       \n",
    "    \n",
    "# return candidates list by joining graphs in Fk\n",
    "def generate_candidates_EB(Fk, k):\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(0, len(Fk)):\n",
    "        sG1 = Fk[i]\n",
    "        \n",
    "        for j in range(i+1, len(Fk)):\n",
    "            sG2 = Fk[j]\n",
    "            match, nmE, nmN = subgraph_match_EB(sG1, sG2)\n",
    "            if match:\n",
    "                c = join_subgraphs_EB(sG1, sG2, nmE, nmN)\n",
    "                if prune_candidate_EB(c, Fk, k):\n",
    "                    candidates.append(c)\n",
    "                \n",
    "    return candidates\n",
    "\n",
    "\n",
    "# generate frequent k+1 sized graphs dict by counting C in g\n",
    "def generate_Fkplus1_EB(C, g, minsup): \n",
    "    Fkplus1 = {}\n",
    "    candidate_is_subgraph = True\n",
    "    support = 0\n",
    "    \n",
    "    for candidate in C:\n",
    "        for graph in g:\n",
    "\n",
    "            # check if graph contains all candidate's nodes\n",
    "            for N in candidate.Nodes():\n",
    "                if not graph.IsNode(N.GetId()):\n",
    "                    candidate_is_subgraph = False\n",
    "                    break\n",
    "\n",
    "            # check if graph contains all candidate's edges    \n",
    "            if candidate_is_subgraph:        \n",
    "                for E in candidate.Edges():\n",
    "                    if not graph.IsEdge(E.GetSrcNId(), E.GetDstNId()):\n",
    "                        candidate_is_subgraph = False\n",
    "                        break\n",
    "\n",
    "            # increment support            \n",
    "            if candidate_is_subgraph:\n",
    "                support += 1\n",
    "\n",
    "            # reset for next graph\n",
    "            candidate_is_subgraph = True\n",
    "\n",
    "        if support >= minsup:\n",
    "            Fkplus1[candidate] = support\n",
    "\n",
    "        support = 0 # reset support for next candidate\n",
    "    \n",
    "    return Fkplus1\n",
    "\n",
    "\n",
    "'''\n",
    "NOTE: (update_FsG)\n",
    "This method is not optimized because it is not necessary.\n",
    "But it is used because if there cycles in the graphs,\n",
    "duplicate entries are appended to FsG\n",
    "'''\n",
    "# return FsG after appending subgraphs not in FsG from Fk\n",
    "def update_FsG_EB(Fk, FsG):\n",
    "    exists = False\n",
    "\n",
    "    for g in Fk.keys(): \n",
    "        for G in FsG.keys():\n",
    "            \n",
    "            if compare_graphs(g, G):\n",
    "                exists = True\n",
    "                \n",
    "        if not exists:\n",
    "            FsG[g] = Fk[g]\n",
    "            \n",
    "        exists = False\n",
    "        \n",
    "    return FsG\n",
    "\n",
    "\n",
    "# return dict with frequent subgraphs and support\n",
    "def edge_based_join_growth(g, minsup):\n",
    "    \n",
    "    # ES = { [ [(SrcNodeId), (DstNodeId) : Support] }\n",
    "    ES = get_all_edge_supports(g)\n",
    "\n",
    "    # F1 = { All frequent singleton graphs }\n",
    "    Fk = get_frequent_singleton_graphs_EB(ES, minsup)\n",
    "    k = 1\n",
    "    \n",
    "    FsG = Fk # all frequent subgraphs\n",
    "    C = [] # candidates from Fk\n",
    "    \n",
    "    # Apriori Algotithm\n",
    "    while(True):\n",
    "        C = generate_candidates_EB(list(Fk.keys()), k+1)\n",
    "        Fk = generate_Fkplus1_EB(C, g, minsup)\n",
    "        \n",
    "        # end if no more frequent subgraphs\n",
    "        if not Fk:\n",
    "            break\n",
    "        FsG = update_FsG_EB(Fk, FsG) # append all frequent subgraphs\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "    return FsG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main:\n",
    "\n",
    "The following cell is used to set the following parameters:  \n",
    "<br>\n",
    "```input_type```: 1 - to use test-graphs or 2 - to use random graphs  \n",
    "```input_graphs_path```: Path to directory with input graphs (txt files)  \n",
    "```numNodes```: Number of Nodes in each graph for generating random graphs  \n",
    "```numEdges```: Number of Edges in each graph for generating random graphs  \n",
    "```numGraphs```: Total number of graphs in graph database  \n",
    "```minsup```: Minimum support  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 1\n",
    "\n",
    "input_graphs_path = \"./datasets/test-graphs2/*.txt\"\n",
    "\n",
    "numNodes = 1000\n",
    "numEdges = 5000\n",
    "numGraphs = 4\n",
    "\n",
    "minsup = 3\n",
    "\n",
    "# g = [G1, G2, G3 ... Gn] \n",
    "if input_type == 1:\n",
    "    g = get_graph_database(\"./datasets/test-graphs/*.txt\")\n",
    "elif input_type == 2:\n",
    "    g = get_random_graph_database(numNodes, numEdges, numGraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses node-based join growth to mine frequent subgraphs and displays the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: [(1, 5)], Support: 4\n",
      "Graph: [(1, 12)], Support: 4\n",
      "Graph: [(5, 6)], Support: 4\n",
      "Graph: [(4, 12)], Support: 4\n",
      "Graph: [(13, 19)], Support: 4\n",
      "Graph: [(19, 20)], Support: 4\n",
      "Graph: [(3, 8)], Support: 4\n",
      "Graph: [(3, 9)], Support: 4\n",
      "Graph: [(3, 11)], Support: 4\n",
      "Graph: [(8, 9)], Support: 4\n",
      "Graph: [(4, 6)], Support: 4\n",
      "Graph: [(13, 18)], Support: 4\n",
      "Graph: [(18, 20)], Support: 4\n",
      "Graph: [(1, 5), (1, 12)], Support: 4\n",
      "Graph: [(5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 12), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (5, 6)], Support: 4\n",
      "Graph: [(4, 6), (4, 12)], Support: 4\n",
      "Graph: [(19, 20), (13, 19)], Support: 4\n",
      "Graph: [(13, 18), (13, 19)], Support: 4\n",
      "Graph: [(18, 20), (19, 20)], Support: 4\n",
      "Graph: [(3, 8), (3, 9)], Support: 4\n",
      "Graph: [(3, 8), (3, 9), (8, 9)], Support: 4\n",
      "Graph: [(3, 8), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 8)], Support: 4\n",
      "Graph: [(3, 9), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 9)], Support: 4\n",
      "Graph: [(18, 20), (13, 18)], Support: 4\n",
      "Graph: [(5, 6), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 12), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6)], Support: 4\n",
      "Graph: [(13, 18), (13, 19), (19, 20)], Support: 4\n",
      "Graph: [(13, 18), (13, 19), (18, 20), (19, 20)], Support: 4\n",
      "Graph: [(18, 20), (19, 20), (13, 19)], Support: 4\n",
      "Graph: [(18, 20), (13, 18), (13, 19)], Support: 4\n",
      "Graph: [(18, 20), (13, 18), (19, 20)], Support: 4\n",
      "Graph: [(3, 8), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 8), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 8), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(4, 12), (1, 5), (1, 12), (5, 6)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (1, 5), (1, 12), (5, 6)], Support: 4\n",
      "Graph: [(4, 6), (5, 6), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6), (1, 12)], Support: 4\n",
      "Total:  48\n"
     ]
    }
   ],
   "source": [
    "# FsG = Frequent subgraphs (with Node-based Join Growth)\n",
    "FsG = node_based_join_growth(g, minsup)\n",
    "\n",
    "# Print Results\n",
    "print_dict(FsG, \"graph\")\n",
    "print(\"Total: \", len(FsG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses edge-based join growth to mine frequent subgraphs and displays the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: [(1, 5)], Support: 4\n",
      "Graph: [(1, 12)], Support: 4\n",
      "Graph: [(5, 6)], Support: 4\n",
      "Graph: [(19, 20)], Support: 4\n",
      "Graph: [(3, 8)], Support: 4\n",
      "Graph: [(3, 9)], Support: 4\n",
      "Graph: [(3, 11)], Support: 4\n",
      "Graph: [(8, 9)], Support: 4\n",
      "Graph: [(4, 6)], Support: 4\n",
      "Graph: [(4, 12)], Support: 4\n",
      "Graph: [(13, 18)], Support: 4\n",
      "Graph: [(13, 19)], Support: 4\n",
      "Graph: [(18, 20)], Support: 4\n",
      "Graph: [(1, 5), (1, 12)], Support: 4\n",
      "Graph: [(5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 12), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (5, 6)], Support: 4\n",
      "Graph: [(13, 19), (19, 20)], Support: 4\n",
      "Graph: [(18, 20), (19, 20)], Support: 4\n",
      "Graph: [(3, 8), (3, 9)], Support: 4\n",
      "Graph: [(3, 8), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 8)], Support: 4\n",
      "Graph: [(3, 9), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 9)], Support: 4\n",
      "Graph: [(4, 6), (4, 12)], Support: 4\n",
      "Graph: [(13, 18), (13, 19)], Support: 4\n",
      "Graph: [(18, 20), (13, 18)], Support: 4\n",
      "Graph: [(5, 6), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 12), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6)], Support: 4\n",
      "Graph: [(18, 20), (19, 20), (13, 19)], Support: 4\n",
      "Graph: [(13, 18), (13, 19), (19, 20)], Support: 4\n",
      "Graph: [(18, 20), (13, 18), (19, 20)], Support: 4\n",
      "Graph: [(3, 8), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 8), (3, 9)], Support: 4\n",
      "Graph: [(8, 9), (3, 8), (3, 11)], Support: 4\n",
      "Graph: [(8, 9), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(18, 20), (13, 18), (13, 19)], Support: 4\n",
      "Graph: [(4, 12), (1, 5), (1, 12), (5, 6)], Support: 4\n",
      "Graph: [(4, 6), (5, 6), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (1, 5), (1, 12)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6), (1, 5)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6), (1, 12)], Support: 4\n",
      "Graph: [(13, 18), (13, 19), (19, 20), (18, 20)], Support: 4\n",
      "Graph: [(8, 9), (3, 8), (3, 9), (3, 11)], Support: 4\n",
      "Graph: [(4, 6), (4, 12), (5, 6), (1, 5), (1, 12)], Support: 4\n",
      "Total:  48\n"
     ]
    }
   ],
   "source": [
    "# FsG_EB = Frequent subgraphs (with Edge-based Join Growth)\n",
    "FsG_EB = edge_based_join_growth(g, minsup)\n",
    "\n",
    "# Print Results\n",
    "print_dict(FsG_EB, \"graph\")\n",
    "print(\"Total: \", len(FsG_EB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
